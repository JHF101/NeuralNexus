{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow tensorflow-hub\n",
    "# !pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import torch\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_label_map = {\n",
    "    1: 'person', 2: 'bicycle', 3: 'car', 4: 'motorcycle', 5: 'airplane',\n",
    "    6: 'bus', 7: 'train', 8: 'truck', 9: 'boat', 10: 'traffic light',\n",
    "    11: 'fire hydrant', 13: 'stop sign', 14: 'parking meter', 15: 'bench',\n",
    "    16: 'bird', 17: 'cat', 18: 'dog', 19: 'horse', 20: 'sheep', 21: 'cow',\n",
    "    22: 'elephant', 23: 'bear', 24: 'zebra', 25: 'giraffe', 27: 'backpack',\n",
    "    28: 'umbrella', 31: 'handbag', 32: 'tie', 33: 'suitcase', 34: 'frisbee',\n",
    "    35: 'skis', 36: 'snowboard', 37: 'sports ball', 38: 'kite', 39: 'baseball bat',\n",
    "    40: 'baseball glove', 41: 'skateboard', 42: 'surfboard', 43: 'tennis racket',\n",
    "    44: 'bottle', 46: 'wine glass', 47: 'cup', 48: 'fork', 49: 'knife', 50: 'spoon',\n",
    "    51: 'bowl', 52: 'banana', 53: 'apple', 54: 'sandwich', 55: 'orange', 56: 'broccoli',\n",
    "    57: 'carrot', 58: 'hot dog', 59: 'pizza', 60: 'donut', 61: 'cake', 62: 'chair',\n",
    "    63: 'couch', 64: 'potted plant', 65: 'bed', 67: 'dining table', 70: 'toilet',\n",
    "    72: 'tv', 73: 'laptop', 74: 'mouse', 75: 'remote', 76: 'keyboard', 77: 'cell phone',\n",
    "    78: 'microwave', 79: 'oven', 80: 'toaster', 81: 'sink', 82: 'refrigerator',\n",
    "    84: 'book', 85: 'clock', 86: 'vase', 87: 'scissors', 88: 'teddy bear',\n",
    "    89: 'hair drier', 90: 'toothbrush'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_models():\n",
    "    \"\"\"\n",
    "    Load the MobileNet and YOLO models.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    mobilenet_model : tensorflow.Module\n",
    "        The loaded MobileNet model from TensorFlow Hub.\n",
    "    yolo_model : torch.nn.Module\n",
    "        The loaded YOLOv5 model from Ultralytics.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> mobilenet_model, yolo_model = load_models()\n",
    "    \"\"\"\n",
    "    mobilenet_model = hub.load(\"https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2\")\n",
    "    yolo_model = torch.hub.load('ultralytics/yolov5', 'yolov5s')\n",
    "    return mobilenet_model, yolo_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_frame(frame, width=None, height=None):\n",
    "    \"\"\"\n",
    "    Resize a video frame to the specified width and height while maintaining the aspect ratio.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    frame : numpy.ndarray\n",
    "        The input video frame.\n",
    "    width : int, optional\n",
    "        The desired width of the resized frame. If None, the width will be calculated based on the height.\n",
    "    height : int, optional\n",
    "        The desired height of the resized frame. If None, the height will be calculated based on the width.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    resized_frame : numpy.ndarray\n",
    "        The resized video frame.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> resized_frame = resize_frame(frame, width=640)\n",
    "    \"\"\"\n",
    "    if width is None and height is None:\n",
    "        return frame\n",
    "\n",
    "    h, w = frame.shape[:2]\n",
    "    if width and height:\n",
    "        # Both width and height are specified\n",
    "        resized_frame = cv2.resize(frame, (width, height))\n",
    "    elif width:\n",
    "        # Only width is specified, calculate height to maintain aspect ratio\n",
    "        ratio = width / float(w)\n",
    "        resized_frame = cv2.resize(frame, (width, int(h * ratio)))\n",
    "    elif height:\n",
    "        # Only height is specified, calculate width to maintain aspect ratio\n",
    "        ratio = height / float(h)\n",
    "        resized_frame = cv2.resize(frame, (int(w * ratio), height))\n",
    "\n",
    "    return resized_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_results_yolo(frame, model):\n",
    "    \"\"\"\n",
    "    Process the YOLO model detections and draw bounding boxes on the frame.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    frame : numpy.ndarray\n",
    "        The input video frame.\n",
    "    model : torch.nn.Module\n",
    "        The YOLO model.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    frame : numpy.ndarray\n",
    "        The frame with drawn bounding boxes and labels.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> processed_frame = process_results_yolo(frame, yolo_model)\n",
    "    \"\"\"\n",
    "    detections = model(frame)\n",
    "\n",
    "    # Filter detections for people (class 0) and clothing (class 2)\n",
    "    selected_detections = detections.pandas().xyxy[0]\n",
    "    selected_detections = selected_detections[(selected_detections['class'] == 0) | (selected_detections['class'] == 2)]\n",
    "\n",
    "    # Draw bounding boxes for selected detections and print classes\n",
    "    for _, detection in selected_detections.iterrows():\n",
    "        x1, y1, x2, y2 = detection['xmin'], detection['ymin'], detection['xmax'], detection['ymax']\n",
    "        x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "        frame = cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "        # Print class\n",
    "        class_name = detection['name']\n",
    "        confidence = detection['confidence']\n",
    "\n",
    "        # Display class name and confidence at top-left corner of bounding box\n",
    "        text = f'{class_name}: {confidence:.2f}'\n",
    "        cv2.putText(frame, text, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_results_mobilenet(frame, model):\n",
    "    \"\"\"\n",
    "    Process the MobileNet model detections and draw bounding boxes on the frame.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    frame : numpy.ndarray\n",
    "        The input video frame.\n",
    "    model : tensorflow.Module\n",
    "        The MobileNet model.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    frame : numpy.ndarray\n",
    "        The frame with drawn bounding boxes and labels.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> processed_frame = process_results_mobilenet(frame, mobilenet_model)\n",
    "    \"\"\"\n",
    "    # Convert frame to tensor and perform detection\n",
    "    input_tensor = tf.convert_to_tensor(frame)\n",
    "    input_tensor = input_tensor[tf.newaxis, ...]\n",
    "    detections = model(input_tensor)\n",
    "\n",
    "    # Process detections from the dictionary format\n",
    "    num_detections = int(detections.pop('num_detections'))\n",
    "    detections = {key: value[0, :num_detections].numpy() for key, value in detections.items()}\n",
    "    detections['num_detections'] = num_detections\n",
    "\n",
    "    detection_boxes = detections['detection_boxes']\n",
    "    detection_scores = detections['detection_scores']\n",
    "    detection_classes = detections['detection_classes'].astype(np.uint8)\n",
    "\n",
    "    # Iterate over each detection\n",
    "    for i in range(num_detections):\n",
    "        # confidence of prediction\n",
    "        confidence = detection_scores[i]\n",
    "        # set confidence level threshold to filter weak predictions\n",
    "        if confidence > 0.5:\n",
    "            # get class id\n",
    "            class_id = int(detection_classes[i])\n",
    "            class_name = coco_label_map[class_id]\n",
    "\n",
    "            # scale to the frame\n",
    "            y1, x1, y2, x2 = detection_boxes[i]\n",
    "            y_top_left = int(y1 * frame.shape[0])\n",
    "            x_top_left = int(x1 * frame.shape[1])\n",
    "            y_bottom_right = int(y2 * frame.shape[0])\n",
    "            x_bottom_right = int(x2 * frame.shape[1])\n",
    "\n",
    "            # draw bounding box around the detected object\n",
    "            cv2.rectangle(frame, (x_top_left, y_top_left), (x_bottom_right, y_bottom_right), (0, 255, 0), 2)\n",
    "\n",
    "            # Add class label and confidence at the top of the bounding box\n",
    "            label = f'{class_name}: {confidence:.2f}'\n",
    "            (label_width, label_height), baseline = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)\n",
    "            cv2.rectangle(frame, (x_top_left, y_top_left - label_height - 10),\n",
    "                        (x_top_left + label_width, y_top_left - 10), (0, 0, 0), cv2.FILLED)\n",
    "            cv2.putText(frame, label, (x_top_left, y_top_left - 5),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_results(frame, model, model_type='tf'):\n",
    "    \"\"\"\n",
    "    Process the detections from the specified model and draw bounding boxes on the frame.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    frame : numpy.ndarray\n",
    "        The input video frame.\n",
    "    model : object\n",
    "        The model to use for detection (MobileNet or YOLO).\n",
    "    model_type : str, optional\n",
    "        The type of the model ('mobilenet' or 'yolo'). Default is 'tf'.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    frame : numpy.ndarray\n",
    "        The frame with drawn bounding boxes and labels.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> processed_frame = process_results(frame, mobilenet_model, model_type='mobilenet')\n",
    "    \"\"\"\n",
    "    # Resize frame to reduce computation\n",
    "    resized_frame = resize_frame(frame, width=640, height=None)  # Adjust dimensions as needed\n",
    "\n",
    "    if model_type == 'mobilenet':\n",
    "        process_results_mobilenet(resized_frame, model)\n",
    "    elif model_type == 'yolo':\n",
    "        process_results_yolo(resized_frame, model)\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_model(model, model_type, frame, iterations=10):\n",
    "    \"\"\"\n",
    "    Benchmark the specified model by measuring the average processing time over a number of iterations.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : object\n",
    "        The model to benchmark (MobileNet or YOLO).\n",
    "    model_type : str\n",
    "        The type of the model ('mobilenet' or 'yolo').\n",
    "    frame : numpy.ndarray\n",
    "        The input video frame.\n",
    "    iterations : int, optional\n",
    "        The number of iterations to run the benchmark. Default is 10.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    avg_time : float\n",
    "        The average processing time per frame in seconds.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> avg_time = benchmark_model(yolo_model, 'yolo', frame, iterations=10)\n",
    "    \"\"\"\n",
    "    times = []\n",
    "    for _ in range(iterations):\n",
    "        start_time = time.time()\n",
    "        process_results(frame, model, model_type)\n",
    "        end_time = time.time()\n",
    "        times.append(end_time - start_time)\n",
    "\n",
    "    avg_time = sum(times) / len(times)\n",
    "    return avg_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenet_model, yolo_model = load_models()\n",
    "current_model = mobilenet_model\n",
    "current_model_type = 'mobilenet'\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open camera.\")\n",
    "    exit()\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Resize frame\n",
    "    resized_frame = resize_frame(frame, width=640, height=320)\n",
    "\n",
    "    frame = process_results(resized_frame, current_model, current_model_type)\n",
    "    cv2.imshow('Camera Feed', frame)\n",
    "\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "    elif key == ord('m'):\n",
    "        current_model = mobilenet_model\n",
    "        current_model_type = 'mobilenet'\n",
    "    elif key == ord('y'):\n",
    "        current_model = yolo_model\n",
    "        current_model_type = 'yolo'\n",
    "    elif key == ord('b'):\n",
    "        benchmark_mobilenet = benchmark_model(mobilenet_model, 'mobilenet', frame)\n",
    "        benchmark_yolo = benchmark_model(yolo_model, 'torch', frame)\n",
    "        print(f\"MobileNet Model Average Time: {benchmark_mobilenet} seconds\")\n",
    "        print(f\"YOLO Model Average Time: {benchmark_yolo} seconds\")\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow('Object Detection', frame)\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
